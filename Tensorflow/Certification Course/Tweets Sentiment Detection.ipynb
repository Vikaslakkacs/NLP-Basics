{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tweets Sentiment Detection.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOAMWtZh7qIgLeE9TNvB2lj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"UmarLin02YAv","colab_type":"code","colab":{}},"source":["### We are going to train a model with huge data of tweets and predict the sentiment of the tweet\n","#### 0-Negative 2-Neutral and 4- positive\n","#### For word embedding and weights we will load from standford file. For every word it has weights with 100 dimensions\n","#### So vocan size would be all words in the training set."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KX1EEyT2qdx","colab_type":"code","outputId":"8a247ab9-d229-4183-c84d-0cfc224d6438","executionInfo":{"status":"ok","timestamp":1590689172818,"user_tz":-330,"elapsed":7344,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv \\\n","    -O /tmp/training_cleaned.csv\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-28 18:06:09--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.120.128, 2607:f8b0:4001:c06::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.120.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 238942690 (228M) [application/octet-stream]\n","Saving to: ‘/tmp/training_cleaned.csv’\n","\n","/tmp/training_clean 100%[===================>] 227.87M   112MB/s    in 2.0s    \n","\n","2020-05-28 18:06:11 (112 MB/s) - ‘/tmp/training_cleaned.csv’ saved [238942690/238942690]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yH7qvXzh4bGi","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow.keras\n","import csv\n","import json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8Kpzhvw4nVD","colab_type":"code","colab":{}},"source":["corpus=[]\n","num_sentences=0\n","with open('/tmp/training_cleaned.csv','r') as csvfile:\n","  csv_data=csv.reader(csvfile,delimiter=',')\n","  for data in csv_data:\n","    ### We will take only first item and 6th item from the list of row\n","    list_row=[]\n","    list_row.append(data[0])\n","    list_row.append(data[5])\n","    corpus.append(list_row)\n","    num_sentences +=1\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOIr15mJ5u2M","colab_type":"code","outputId":"5c090c0b-a5a0-438e-9f1f-03718141e1f7","executionInfo":{"status":"ok","timestamp":1590689180131,"user_tz":-330,"elapsed":14452,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["print(len(corpus))\n","print(num_sentences)\n","corpus[1][1]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1600000\n","1600000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\""]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"pZggJ7rx5_tz","colab_type":"code","colab":{}},"source":["### Now lets start training"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sv4xDWyPGIR0","colab_type":"code","colab":{}},"source":["sentences=[]\n","labels=[]\n","for label,cat in corpus:\n","  sentences.append(cat)\n","  labels.append(int(label))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fbx6u7zaH4ng","colab_type":"code","outputId":"73f28f8a-e40f-44e9-8909-c07781fc2e85","executionInfo":{"status":"ok","timestamp":1590690326090,"user_tz":-330,"elapsed":1657,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(labels)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1600000"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"code","metadata":{"id":"U5T0lfW_GQe3","colab_type":"code","colab":{}},"source":["### WE will split the data 70-30\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s8JObppbHjN-","colab_type":"code","colab":{}},"source":["train_data,test_data,train_labels,test_labels=train_test_split(sentences,labels,test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LJS1J5wiHyP_","colab_type":"code","outputId":"a6a55827-7fdf-4372-c23a-d37f9dd58666","executionInfo":{"status":"ok","timestamp":1590690328004,"user_tz":-330,"elapsed":2745,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(train_data),len(test_data)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1280000, 320000)"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"R_hsgpS5IpKF","colab_type":"code","colab":{}},"source":["### Tokenization"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hrziI4nmKfRw","colab_type":"code","colab":{}},"source":["embed_dim=100\n","max_len=16\n","trunc_text='post'\n","padding='post'\n","oov_token='<OOV>'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qjY2U37ZIs3m","colab_type":"code","colab":{}},"source":[" from tensorflow.keras.preprocessing.text import Tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2leirSw_KcVv","colab_type":"code","colab":{}},"source":["#### we won't assign weights here vocab size here because we have another \n","token=Tokenizer(oov_token=oov_token)\n","token.fit_on_texts(train_data)\n","word_index=token.word_index\n","## now vocab size would be every word in the word_index\n","vocab_size=len(word_index)\n","train_seq=token.texts_to_sequences(train_data)\n","test_seq=token.texts_to_sequences(test_data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZg5e7ELNanY","colab_type":"code","colab":{}},"source":["### Padding Sequence\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"05Rg7lFhPbCZ","colab_type":"code","colab":{}},"source":["train_pad_seq=pad_sequences(train_seq,maxlen=max_len,padding=padding,truncating=trunc_text)\n","test_pad_seq=pad_sequences(test_seq,maxlen=max_len,padding=padding,truncating=trunc_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpdEQOYnPvTH","colab_type":"code","colab":{}},"source":["### Now we have done pre processing.\n","### For embedded weights we will take weights from other sources instead of creating on our own with embedding layer\n","### We are taking from standford Glove dataset. Where it has words weights of 100 dimensions. that is the reason we also defined the wmbed_dim\n","### of 100 dimensions."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lc-C31jfQKj5","colab_type":"code","outputId":"a658dd15-a0aa-4497-d2f3-e4c9d0ce4dce","executionInfo":{"status":"ok","timestamp":1590689257185,"user_tz":-330,"elapsed":90716,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n","    -O /tmp/glove.6B.100d.txt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-05-28 18:07:22--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c09::80\n","Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 347116733 (331M) [text/plain]\n","Saving to: ‘/tmp/glove.6B.100d.txt’\n","\n","/tmp/glove.6B.100d. 100%[===================>] 331.04M  55.4MB/s    in 13s     \n","\n","2020-05-28 18:07:36 (24.5 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_DlcvVc4QZah","colab_type":"code","colab":{}},"source":["### first we will map weights for all the words\n","### Then we will create an empty array with zeros and shape of the weights and then we will assign weights present in our word_index"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcTwTE9kQqs4","colab_type":"code","outputId":"86e2ae39-73d9-4d2b-973f-55c1271ff6c9","executionInfo":{"status":"ok","timestamp":1590689257194,"user_tz":-330,"elapsed":90543,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["\n","with open('/tmp/glove.6B.100d.txt','r',encoding='utf-8',) as filedef:\n","  for lines in filedef:\n","    print(type(lines))\n","    print\n","    break\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'str'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lO8GCaz4RLmZ","colab_type":"code","colab":{}},"source":["### So the line is string with space seperated and first value is word and rest are weights. \n","### We will split and add the weights accordingly.\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMbgIhcLRj8Z","colab_type":"code","colab":{}},"source":["embedded_index={}\n","with open('/tmp/glove.6B.100d.txt','r',encoding='utf-8') as glove:\n","  for lines in glove:\n","    lines_weights=lines.split()\n","    word=lines_weights[0]\n","    weights=np.asarray(lines_weights[1:], dtype=np.float32)\n","    embedded_index[word]=weights"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tuhMb5BcTsAb","colab_type":"code","outputId":"5f5de890-7806-4326-a566-96ff4234170e","executionInfo":{"status":"ok","timestamp":1590689268232,"user_tz":-330,"elapsed":101356,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":312}},"source":["embedded_index['the']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n","       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n","        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n","       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n","        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n","       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n","        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n","        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n","       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n","       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n","       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n","       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n","       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n","       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n","       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n","        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n","       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"_IFq6C_XTDH1","colab_type":"code","colab":{}},"source":["### Now we have got the weights for each word. \n","### We will loop the same with our word_index and then we will assign those weights to out words\n","### we will create an array with zeros and then we will asssign weights which maps with rhe standford glove words"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XztGQ0Q5TgSX","colab_type":"code","colab":{}},"source":["embed_vector=np.zeros((vocab_size+1,100),dtype=np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVeRd0oGThmk","colab_type":"code","outputId":"ec610b05-a27a-4343-f970-9917f3344c1b","executionInfo":{"status":"ok","timestamp":1590690734164,"user_tz":-330,"elapsed":739,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["embed_vector.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(595155, 100)"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"code","metadata":{"id":"Tc2pp4trVifH","colab_type":"code","colab":{}},"source":["for words,i in word_index.items():\n","  # We will search the word in the embed index and if we find then we will takthe index and assign the weights\n","  word_vector=embedded_index.get(words)\n","  \n","  if word_vector is not None:\n","    embed_vector[i] = embedded_index[words]\n","    #break\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1guKWW6bWmF","colab_type":"code","outputId":"f5b71a8e-c5c4-463a-e00c-9318a94ee1cd","executionInfo":{"status":"ok","timestamp":1590690745723,"user_tz":-330,"elapsed":838,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(word_index)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["595154"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"id":"-yQRR0iYVnJJ","colab_type":"code","outputId":"0c5c41bd-e6f4-4251-9eb4-646ede99d28b","executionInfo":{"status":"ok","timestamp":1590690749127,"user_tz":-330,"elapsed":771,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["embed_vector.shape,embed_vector[594436]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((595155, 100),\n"," array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       dtype=float32))"]},"metadata":{"tags":[]},"execution_count":87}]},{"cell_type":"code","metadata":{"id":"CUCZPg_njdD6","colab_type":"code","outputId":"3b282296-1139-47e3-f24d-e82102f06ef8","executionInfo":{"status":"ok","timestamp":1590690700578,"user_tz":-330,"elapsed":843,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["595154"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"id":"gnJD5XUlWpB8","colab_type":"code","colab":{}},"source":["### Now we have got all the weights ffor word index which we usually used to get fropm Embedding layer.\n","### Now we will create model in that , in Embedding layer we will pass these weights of the word index and turn off\n","### the train mode for that particular layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_l23c05MachE","colab_type":"code","colab":{}},"source":["from tensorflow import keras\n","from tensorflow.keras.layers import Embedding,Dense,GlobalAveragePooling1D,Flatten"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IEVad8JEaYAE","colab_type":"code","outputId":"a88a6298-9a5d-4deb-99b9-41678b667cac","executionInfo":{"status":"ok","timestamp":1590691764178,"user_tz":-330,"elapsed":1266,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["model=keras.Sequential()\n","model.add(Embedding(input_dim=vocab_size+1,output_dim=embed_dim,input_length=max_len,weights=[embed_vector],trainable=False))\n","model.add(Flatten())\n","model.add(Dense(units=6,activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 16, 100)           59515500  \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1600)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 6)                 9606      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 7         \n","=================================================================\n","Total params: 59,525,113\n","Trainable params: 9,613\n","Non-trainable params: 59,515,500\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kp3YyCS-cRkr","colab_type":"code","colab":{}},"source":["train_labels=np.asarray(train_labels)\n","test_labels=np.array(test_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"encX7mdngHJM","colab_type":"code","colab":{}},"source":["for num in train_labels:\n","  if num==2:\n","    print(num)\n","    break"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_mOR-LDpaa27","colab_type":"code","outputId":"4305cf34-418d-4ce0-c5ac-b767d0f0ab8e","executionInfo":{"status":"ok","timestamp":1590691395629,"user_tz":-330,"elapsed":635065,"user":{"displayName":"vikas lakka","photoUrl":"","userId":"02419107211909781677"}},"colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["model.fit(train_pad_seq,train_labels,epochs=10,validation_data=(test_pad_seq,test_labels))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","40000/40000 [==============================] - 65s 2ms/step - loss: -45411.9336 - accuracy: 4.2969e-05 - val_loss: -129603.4844 - val_accuracy: 0.0000e+00\n","Epoch 2/10\n","40000/40000 [==============================] - 62s 2ms/step - loss: -289011.4688 - accuracy: 0.0000e+00 - val_loss: -494419.1875 - val_accuracy: 0.0000e+00\n","Epoch 3/10\n","40000/40000 [==============================] - 63s 2ms/step - loss: -782520.5000 - accuracy: 0.0000e+00 - val_loss: -1125557.5000 - val_accuracy: 0.0000e+00\n","Epoch 4/10\n","40000/40000 [==============================] - 64s 2ms/step - loss: -1557981.0000 - accuracy: 0.0000e+00 - val_loss: -2058498.2500 - val_accuracy: 0.0000e+00\n","Epoch 5/10\n","40000/40000 [==============================] - 62s 2ms/step - loss: -2639106.7500 - accuracy: 0.0000e+00 - val_loss: -3296571.2500 - val_accuracy: 0.0000e+00\n","Epoch 6/10\n","40000/40000 [==============================] - 64s 2ms/step - loss: -4022284.7500 - accuracy: 0.0000e+00 - val_loss: -4840238.5000 - val_accuracy: 0.0000e+00\n","Epoch 7/10\n","40000/40000 [==============================] - 62s 2ms/step - loss: -5711174.5000 - accuracy: 0.0000e+00 - val_loss: -6689140.0000 - val_accuracy: 0.0000e+00\n","Epoch 8/10\n","40000/40000 [==============================] - 62s 2ms/step - loss: -7699908.0000 - accuracy: 0.0000e+00 - val_loss: -8840810.0000 - val_accuracy: 0.0000e+00\n","Epoch 9/10\n","40000/40000 [==============================] - 65s 2ms/step - loss: -9992792.0000 - accuracy: 0.0000e+00 - val_loss: -11298632.0000 - val_accuracy: 0.0000e+00\n","Epoch 10/10\n","40000/40000 [==============================] - 65s 2ms/step - loss: -12592636.0000 - accuracy: 0.0000e+00 - val_loss: -14061201.0000 - val_accuracy: 0.0000e+00\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f61fffd9278>"]},"metadata":{"tags":[]},"execution_count":89}]},{"cell_type":"code","metadata":{"id":"3mlwLJ21cKZF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}